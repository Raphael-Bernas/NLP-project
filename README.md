# Quantizer robustness training in Generative Spoken Language Modeling
# (Project 6 for the course "Speech and natural language processing")
https://github.com/chloedaphne/MVA_2025_SNLP/

## Notebook
In the notebook `NLP-project.ipynb` you can find our code used for this project.
The code is divided in 7 parts which have each been done by one of us.

## Paper
You can find our report in the form of a paper. It contains a detailed and explained walk through our works.

## Authors
Raphaël Bernas (ENSTA-MVA), Maxime Corlay (ENSTA-MVA), Adrien Letellier (ENSAE-MVA) and Emilie Zheng (ENS-MVA).


## Task repartion :

a)	To recode the encoder part to have the basics [Adrien]

b)	To recode the quantizer part with the training method introduced in their paper [Raphaël]

c)	To recode testing methods: UED and ABX [Raphaël]

d)	To implement general augmentation and some more [Maxime]

e)	To implement new augmentation (corruption and volume change) [Emilie]

f)	To test models on the original settings [Emilie]

g)	To test new architecture of quantizer for E1 (change the MLP based method) [Raphael]

h)	To test new models [Emilie & Raphael & Maxime]

i)	To suggest other metric, mainly reform the UED metric and Levenshtein distance using Dynamic Time Warping [Adrien] 
